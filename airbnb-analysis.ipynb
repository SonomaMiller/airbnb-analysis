{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Airbnb Analysis\n",
    "**Summary**\n",
    "\n",
    "I am currently writing this from an Airbnb next to Olympic National Park. I became curious about the\n",
    "popularity of Airbnbs in Washington, especially because of Airbnb’s increasing popularity and the\n",
    "resurgence of travel post-pandemic. This analysis targets trends in tourism in Seattle, and uses machine\n",
    "learning to predict where the most profitable Airbnbs will populate in the future. The results can be used by\n",
    "hosts to help boost their ratings and increase the number of bookings, and can help analyze Seattle’s\n",
    "tourism economy as a whole. As an economics major, I am also currently exploring how Airbnb is affecting\n",
    "our local economy; with the regulations being implemented on Airbnbs in New York, I believe it would be\n",
    "interesting to identify whether it’s possible that Seattle would face similar legal challenges. I chose to focus\n",
    "on Seattle specifically in the interest of computer storage and time. Once my code runs successfully, I hope\n",
    "to expand it to multiple cities in order to be able to identify national trends.\n",
    "\n",
    "1. Which neighborhoods in Seattle are the most popular for Airbnbs?\n",
    "2. Which neighborhoods in Seattle contain the most expensive Airbnbs?\n",
    "3. Given different factors, which Airbnbs are predicted to be popular?\n",
    "4. Does having a profile picture affect the popularity of a host's listing?\n",
    "\n",
    "# Challenge Goals\n",
    "In addition to a csv and geodataframe, I am using a geojson for my map, which we did not use in class and\n",
    "is considered messy data. Additionally, I hypothesize that having a host profile picture will increase the\n",
    "number of bookings for their listing. I will be using altair in order to create interactive datasets. I hope to\n",
    "create results that are user-friendly to be used by hosts in order to help them easily understand what factors\n",
    "increase the popularity of Airbnb listings, and for city planners and policymakers to understand trends in\n",
    "Airbnbs throughout Seattle. I have never used this libraries, but the interactive graph at the end of our\n",
    "education assignment intrigued me, and I would like to learn how to do something similar.\n",
    "Additionally, I will be using machine learning to predict the most popular Airbnbs on a longitude-latitude\n",
    "map. I will be using scikit-learn to compare three different classification methods: LinearSVC, Decision Tree\n",
    "Classification, and Random Forest.\n",
    "\n",
    "# Data Setting and Methods\n",
    "I first imported all of my libraries and functions. Then, I loaded in my listings as both a csv and a\n",
    "GeoDataFrame, as well as a map of Seattle as a geojson. I also changed the formats of price to exclude\n",
    "dollar signs so they could be used as a float. In methods, the dataset may be manipulated (such as adding\n",
    "columns), but the specifications above are the only ones consistent throughout all of the code.\n",
    "I have separated my graphs and answers to research questions into different methods. Additionally, there is\n",
    "more analysis in project_code that I opted not to include here due to relevancy and organization. In\n",
    "project_code.ipynb, the last code cell contains a short explanation of each method, as well as a\n",
    "commented line that can be uncommented to run the method. This helps keep my code organized and run\n",
    "efficiently, as opposed to running all code at once. The methods are a combination of number comparisons,\n",
    "graphs, maps, and machine learning classification methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install matplotlib.pyplot\n",
    "!pip install geopandas\n",
    "!pip install numpy\n",
    "!pip install altair\n",
    "!pip install doctest\n",
    "!pip install -q folium mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import doctest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in listings as a csv and gdf, change price to float, load in map as a geojson\n",
    "listing_path = \"listings.csv\"\n",
    "map_path = \"neighbourhoods.geojson\"\n",
    "listings_test = pd.read_csv(\"listings-small.csv\").set_index(\"id\")\n",
    "listings = pd.read_csv(listing_path).set_index(\"id\")\n",
    "listing_gdf = gpd.GeoDataFrame(\n",
    "    listings,\n",
    "    # crs=\"EPSG:4326\" specifies WGS84 or GPS coordinate system, see https://epsg.io/4326\n",
    "    geometry=gpd.points_from_xy(listings[\"longitude\"], listings[\"latitude\"], crs=\"EPSG:4326\")\n",
    ")\n",
    "listings[\"price\"] = listings[\"price\"].replace(\"[\\\\$,]\", \"\", regex=True).astype(float)\n",
    "gjsn = gpd.read_file(map_path)\n",
    "\n",
    "assert listing_path.endswith('.csv'), \"listings must be a csv\"\n",
    "assert map_path.endswith('.geojson'), \"listings must be a geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## 1. Which neighborhoods in Seattle are the most popular for Airbnbs?\n",
    "I found that Broadway and Belltown had the highest number of listings in Seattle, by far. These did not\n",
    "surprise me, as waterfront properties and listings in the heart of Capitol Hill's bustling streets have lots of\n",
    "activities for visitors. I also found that Holly Park and the Industrial District were the least popular; this could be that they have less restaurants and activities, are more expensive to purchase properties, or are more\n",
    "dangerous. Interestingly, I also found that Holly Park had the highest Airbnb rating, which could be due to a\n",
    "lack of Airbnbs there. Visualizations below.\n",
    "## 2. Which neighborhoods in Seattle contain the most expensive Airbnbs?\n",
    "My map found that expensive Airbnbs were fairly evenly distributed among different neighborhoods, with a\n",
    "weak correlation of waterfront properties being more expensive. I also found that the majority of Airbnbs\n",
    "are less than $750, with 99.9% of Airbnbs being less than $2100.\n",
    "## 3. Given different factors, which Airbnbs are predicted to be popular?\n",
    "I found that decision tree binary classification consistently had the highest accuracy of the three methods I\n",
    "used, and is the easiest to understand when visualized. It found that Airbnbs that are cheaper than $145.5\n",
    "and accomodate less than 9.5 people are most likely to be popular. While this means this is a correlation, it\n",
    "is also possible that these Airbnbs are just booked more often due to affordability and accomodation needs.\n",
    "## 4. Does having a profile picture affect the popularity of a host's listing?\n",
    "Surprisingly, my analysis found that the mean number of bookings for hosts with profile pictures was\n",
    "actually less than those with a profile picture. However, the median for hosts with profile pictures is greater\n",
    "than those without. This leads me to conclude that there are outliers with profile pictures and no bookings\n",
    "that are affecting the mean, and my hypothesis can be neither proved nor disproved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-00ba2bce3aea415fa6f21d8d1a7426ca.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-00ba2bce3aea415fa6f21d8d1a7426ca.vega-embed details,\n",
       "  #altair-viz-00ba2bce3aea415fa6f21d8d1a7426ca.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-00ba2bce3aea415fa6f21d8d1a7426ca\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-00ba2bce3aea415fa6f21d8d1a7426ca\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-00ba2bce3aea415fa6f21d8d1a7426ca\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-713fb5c8fe85c8b678fe7067f0127ffe\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"neighbourhood_cleansed\", \"type\": \"nominal\"}, {\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"neighbourhood_cleansed\", \"title\": \"Neighbourhood\", \"type\": \"nominal\"}, \"y\": {\"field\": \"count\", \"title\": \"Number of Listings\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Number of Airbnb Listings by Neighbourhood\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-713fb5c8fe85c8b678fe7067f0127ffe\": [{\"neighbourhood_cleansed\": \"Adams\", \"count\": 129}, {\"neighbourhood_cleansed\": \"Alki\", \"count\": 108}, {\"neighbourhood_cleansed\": \"Arbor Heights\", \"count\": 23}, {\"neighbourhood_cleansed\": \"Atlantic\", \"count\": 127}, {\"neighbourhood_cleansed\": \"Belltown\", \"count\": 339}, {\"neighbourhood_cleansed\": \"Bitter Lake\", \"count\": 32}, {\"neighbourhood_cleansed\": \"Briarcliff\", \"count\": 17}, {\"neighbourhood_cleansed\": \"Brighton\", \"count\": 64}, {\"neighbourhood_cleansed\": \"Broadview\", \"count\": 27}, {\"neighbourhood_cleansed\": \"Broadway\", \"count\": 363}, {\"neighbourhood_cleansed\": \"Bryant\", \"count\": 46}, {\"neighbourhood_cleansed\": \"Cedar Park\", \"count\": 22}, {\"neighbourhood_cleansed\": \"Central Business District\", \"count\": 119}, {\"neighbourhood_cleansed\": \"Columbia City\", \"count\": 112}, {\"neighbourhood_cleansed\": \"Crown Hill\", \"count\": 39}, {\"neighbourhood_cleansed\": \"Dunlap\", \"count\": 22}, {\"neighbourhood_cleansed\": \"East Queen Anne\", \"count\": 116}, {\"neighbourhood_cleansed\": \"Eastlake\", \"count\": 100}, {\"neighbourhood_cleansed\": \"Fairmount Park\", \"count\": 51}, {\"neighbourhood_cleansed\": \"Fauntleroy\", \"count\": 34}, {\"neighbourhood_cleansed\": \"First Hill\", \"count\": 133}, {\"neighbourhood_cleansed\": \"Fremont\", \"count\": 214}, {\"neighbourhood_cleansed\": \"Gatewood\", \"count\": 42}, {\"neighbourhood_cleansed\": \"Genesee\", \"count\": 39}, {\"neighbourhood_cleansed\": \"Georgetown\", \"count\": 22}, {\"neighbourhood_cleansed\": \"Green Lake\", \"count\": 141}, {\"neighbourhood_cleansed\": \"Greenwood\", \"count\": 126}, {\"neighbourhood_cleansed\": \"Haller Lake\", \"count\": 68}, {\"neighbourhood_cleansed\": \"Harrison/Denny-Blaine\", \"count\": 30}, {\"neighbourhood_cleansed\": \"High Point\", \"count\": 17}, {\"neighbourhood_cleansed\": \"Highland Park\", \"count\": 29}, {\"neighbourhood_cleansed\": \"Holly Park\", \"count\": 1}, {\"neighbourhood_cleansed\": \"Industrial District\", \"count\": 1}, {\"neighbourhood_cleansed\": \"Interbay\", \"count\": 20}, {\"neighbourhood_cleansed\": \"International District\", \"count\": 30}, {\"neighbourhood_cleansed\": \"Laurelhurst\", \"count\": 24}, {\"neighbourhood_cleansed\": \"Lawton Park\", \"count\": 58}, {\"neighbourhood_cleansed\": \"Leschi\", \"count\": 56}, {\"neighbourhood_cleansed\": \"Lower Queen Anne\", \"count\": 120}, {\"neighbourhood_cleansed\": \"Loyal Heights\", \"count\": 67}, {\"neighbourhood_cleansed\": \"Madison Park\", \"count\": 14}, {\"neighbourhood_cleansed\": \"Madrona\", \"count\": 35}, {\"neighbourhood_cleansed\": \"Mann\", \"count\": 99}, {\"neighbourhood_cleansed\": \"Maple Leaf\", \"count\": 52}, {\"neighbourhood_cleansed\": \"Matthews Beach\", \"count\": 28}, {\"neighbourhood_cleansed\": \"Meadowbrook\", \"count\": 11}, {\"neighbourhood_cleansed\": \"Mid-Beacon Hill\", \"count\": 68}, {\"neighbourhood_cleansed\": \"Minor\", \"count\": 217}, {\"neighbourhood_cleansed\": \"Montlake\", \"count\": 49}, {\"neighbourhood_cleansed\": \"Mount Baker\", \"count\": 81}, {\"neighbourhood_cleansed\": \"North Admiral\", \"count\": 100}, {\"neighbourhood_cleansed\": \"North Beach/Blue Ridge\", \"count\": 31}, {\"neighbourhood_cleansed\": \"North Beacon Hill\", \"count\": 140}, {\"neighbourhood_cleansed\": \"North College Park\", \"count\": 41}, {\"neighbourhood_cleansed\": \"North Delridge\", \"count\": 42}, {\"neighbourhood_cleansed\": \"North Queen Anne\", \"count\": 120}, {\"neighbourhood_cleansed\": \"Olympic Hills\", \"count\": 25}, {\"neighbourhood_cleansed\": \"Phinney Ridge\", \"count\": 94}, {\"neighbourhood_cleansed\": \"Pike-Market\", \"count\": 85}, {\"neighbourhood_cleansed\": \"Pinehurst\", \"count\": 31}, {\"neighbourhood_cleansed\": \"Pioneer Square\", \"count\": 47}, {\"neighbourhood_cleansed\": \"Portage Bay\", \"count\": 21}, {\"neighbourhood_cleansed\": \"Rainier Beach\", \"count\": 64}, {\"neighbourhood_cleansed\": \"Rainier View\", \"count\": 9}, {\"neighbourhood_cleansed\": \"Ravenna\", \"count\": 98}, {\"neighbourhood_cleansed\": \"Riverview\", \"count\": 36}, {\"neighbourhood_cleansed\": \"Roosevelt\", \"count\": 53}, {\"neighbourhood_cleansed\": \"Roxhill\", \"count\": 10}, {\"neighbourhood_cleansed\": \"Seaview\", \"count\": 37}, {\"neighbourhood_cleansed\": \"Seward Park\", \"count\": 54}, {\"neighbourhood_cleansed\": \"South Beacon Hill\", \"count\": 37}, {\"neighbourhood_cleansed\": \"South Delridge\", \"count\": 45}, {\"neighbourhood_cleansed\": \"South Lake Union\", \"count\": 150}, {\"neighbourhood_cleansed\": \"South Park\", \"count\": 27}, {\"neighbourhood_cleansed\": \"Southeast Magnolia\", \"count\": 26}, {\"neighbourhood_cleansed\": \"Stevens\", \"count\": 131}, {\"neighbourhood_cleansed\": \"Sunset Hill\", \"count\": 34}, {\"neighbourhood_cleansed\": \"University District\", \"count\": 241}, {\"neighbourhood_cleansed\": \"Victory Heights\", \"count\": 27}, {\"neighbourhood_cleansed\": \"View Ridge\", \"count\": 15}, {\"neighbourhood_cleansed\": \"Wallingford\", \"count\": 235}, {\"neighbourhood_cleansed\": \"Wedgwood\", \"count\": 27}, {\"neighbourhood_cleansed\": \"West Queen Anne\", \"count\": 113}, {\"neighbourhood_cleansed\": \"West Woodland\", \"count\": 107}, {\"neighbourhood_cleansed\": \"Westlake\", \"count\": 15}, {\"neighbourhood_cleansed\": \"Whittier Heights\", \"count\": 61}, {\"neighbourhood_cleansed\": \"Windermere\", \"count\": 16}, {\"neighbourhood_cleansed\": \"Yesler Terrace\", \"count\": 71}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Column(s) review_scores_rating already selected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m listing_df_clean \u001b[38;5;241m=\u001b[39m listings\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_scores_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     26\u001b[0m neighbourhood_stats \u001b[38;5;241m=\u001b[39m listing_df_clean\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneighbourhood_cleansed\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_scores_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m neighbourhood_stats \u001b[38;5;241m=\u001b[39m neighbourhood_stats[\u001b[43mneighbourhood_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m neighbourhood_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m neighbourhood_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     29\u001b[0m mean_rating \u001b[38;5;241m=\u001b[39m neighbourhood_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\base.py:234\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already selected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, ABCSeries, ABCIndex, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mintersection(key)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)):\n",
      "\u001b[1;31mIndexError\u001b[0m: Column(s) review_scores_rating already selected"
     ]
    }
   ],
   "source": [
    "# 1. Which neighborhoods in Seattle are the most popular for Airbnbs?\n",
    "\"\"\"\n",
    "explore an interactive map of all listings in Seattle\n",
    "\"\"\"\n",
    "listing_gdf.explore(column=\"neighbourhood_group_cleansed\")\n",
    "\n",
    "\"\"\"\n",
    "plots a bar chart with each neighborhood in Seattle (x-axis) and the number of Airbnbs as the y-axis\n",
    "Made interactive using altair due to large num of neighbourhoods.\n",
    "\"\"\"\n",
    "neighbourhood_counts = listings.groupby(\"neighbourhood_cleansed\").size().reset_index(name=\"count\")\n",
    "\n",
    "num_chart = alt.Chart(neighbourhood_counts).mark_bar().encode(\n",
    "    x=alt.X(\"neighbourhood_cleansed:N\", title=\"Neighbourhood\"),\n",
    "    y=alt.Y(\"count:Q\", title=\"Number of Listings\"),\n",
    "    tooltip=[\"neighbourhood_cleansed\", \"count\"]\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=\"Number of Airbnb Listings by Neighbourhood\"\n",
    ").interactive()\n",
    "\n",
    "num_chart.display()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plots a bar chart with each neighborhood in Seattle (x-axis) and the average rating of Airbnbs as the y-axis.\n",
    "Made interactive using altair\n",
    "\"\"\"\n",
    "listing_df_clean = listings.dropna(subset=[\"review_scores_rating\"])\n",
    "neighbourhood_stats = listing_df_clean.groupby(\"neighbourhood_cleansed\")[\"review_scores_rating\"].agg([\"mean\", \"count\"])\n",
    "neighbourhood_stats = neighbourhood_stats[neighbourhood_stats[\"count\"] > 0]\n",
    "neighbourhood_stats[\"mean\"] = neighbourhood_stats[\"mean\"].round(2)\n",
    "mean_rating = neighbourhood_stats[\"mean\"].to_dict()\n",
    "\n",
    "neighbourhood_stats_altair = neighbourhood_stats.reset_index()\n",
    "\n",
    "rating_chart = alt.Chart(neighbourhood_stats_altair).mark_bar().encode(\n",
    "    x=\"neighbourhood_cleansed:N\",\n",
    "    y=\"mean:Q\",\n",
    "    tooltip=[\"neighbourhood_cleansed\", \"mean\"]\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=\"Mean Ratings by Neighbourhood\"\n",
    ").interactive()\n",
    "\n",
    "rating_chart.display()\n",
    "\n",
    "unique = listings.neighbourhood_cleansed.unique()\n",
    "assert len(unique) == 88, \"Number of neighbourhoods does not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Which neighborhoods in Seattle contain the most expensive Airbnbs?\n",
    "# What does the price distribution of Airbnbs look like?\n",
    "\"\"\"\n",
    "Maps a histogram of prices\n",
    "\"\"\"\n",
    "listings_filtered = listings[listings[\"price\"] <= 2100]\n",
    "\n",
    "plt.hist(listings_filtered[\"price\"], bins=20, edgecolor=\"black\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Prices Minus 99.9th Percentile Outliers\")\n",
    "# ax.set_ylim(ymax=2000)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Creates a scatterplot representing a map of Seattle and the average price\n",
    "of Airbnbs (red = more expensive, blue = cheaper)\n",
    "\"\"\"\n",
    "# the price threshold can be changed. I found that including listings above this made it difficult to\n",
    "# distinguish different prices on the map, because the majority of them are <= $400.\n",
    "price_threshold = 400\n",
    "\n",
    "listings_filtered = listings[listings[\"price\"] <= price_threshold]\n",
    "\n",
    "latitude = listings_filtered[\"latitude\"]\n",
    "longitude = listings_filtered[\"longitude\"]\n",
    "price = listings_filtered[\"price\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "gjsn.plot(ax=ax, color=\"#EEE\")\n",
    "\n",
    "sc = ax.scatter(longitude, latitude, c=price, cmap=\"coolwarm\", alpha=0.7)\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Price of Airbnb Listings Under $\" + str(price_threshold))\n",
    "\n",
    "# USED AI IN LINE 23: prompt: what is *sc matplotlib\n",
    "legend1 = ax.legend(*sc.legend_elements(), title=\"Price\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "assert ax.get_xlabel() == \"Longitude\", \"x-label must be longitude\"\n",
    "assert ax.get_ylabel() == \"Latitude\", \"y-label must be latitude\"\n",
    "for i in listings_filtered[\"price\"]:\n",
    "    assert i <= int(price_threshold), \"all prices included must be <= threshold\"\n",
    "    assert i > 0, \"all prices must be greater than 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Given different factors, which Airbnbs are predicted to be popular?\n",
    "def linear_svc(listings) -> float:\n",
    "    \"\"\"\n",
    "    Use LinearSVC to determine whether availability_365 will be <= 92 (listing is popular) or\n",
    "    > 92 (listing is not as popular). Find mse and accuracy\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    listings_cleaned = listings.dropna(subset=[\"price\", \"accommodates\"]).copy()\n",
    "    listings_cleaned[\"popular\"] = (listings_cleaned[\"availability_365\"] <= 92).astype(int)\n",
    "\n",
    "    X = listings_cleaned[[\"price\", \"accommodates\"]]\n",
    "    y = listings_cleaned[\"popular\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    clf = LinearSVC(max_iter=1000000, dual=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of Model:\", accuracy)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    return mse\n",
    "\n",
    "def decision_tree(listings) -> float:\n",
    "    \"\"\"\n",
    "    Use decision tree regression to determine whether listing will be popular. Find mse and accuracy\n",
    "\n",
    "    Interpreting the decision tree (more of a personal note): value[0] is the proportion of samples that are\n",
    "    labeled not popular, and value[1] is the proportion that are labeled popular.\n",
    "    \"\"\"\n",
    "    listings_cleaned = listings.dropna(subset=[\"price\", \"accommodates\", \"review_scores_rating\", \"host_response_rate\"]).copy()\n",
    "    listings_cleaned[\"popular\"] = (listings_cleaned[\"availability_365\"] <= 92).astype(int)\n",
    "    listings_cleaned[\"host_response_rate\"] = listings_cleaned[\"host_response_rate\"].str.rstrip(\"%\").astype(float) / 100\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    X = listings_cleaned[[\"price\", \"accommodates\", \"review_scores_rating\", \"host_response_rate\"]]\n",
    "    y = listings_cleaned[\"popular\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    tree_class = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    tree_class.fit(X_train, y_train)\n",
    "    accuracy = tree_class.score(X_test, y_test)\n",
    "\n",
    "    # Visualize Decision Tree\n",
    "    plt.figure(dpi=300)\n",
    "    plot_tree(\n",
    "        tree_class,\n",
    "        feature_names=X.columns,\n",
    "        filled=True,\n",
    "        impurity=False,\n",
    "        proportion=True,\n",
    "        rounded=False,\n",
    "        max_depth=3\n",
    "    )\n",
    "\n",
    "    print(\"Accuracy of Model:\", accuracy)\n",
    "    # check significance\n",
    "    importances = tree_class.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    for feature, importance in zip(feature_names, importances):\n",
    "        print(feature, importance)\n",
    "\n",
    "    y_pred = tree_class.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "    # I really don't need to return stuff, but I wanted to use it to practice different types of tests\n",
    "    return mse\n",
    "\n",
    "def random_forest(listings) -> float:\n",
    "    \"\"\"\n",
    "    Use random forest to estimate which listings will be popular (available for <= than 1/4 the year). Find mse and accuracy\n",
    "    \"\"\"\n",
    "    # drop na values, create popular column (available for <= 1/4 of year)\n",
    "    listings_cleaned = listings.dropna(subset=[\"price\", \"accommodates\"]).copy()\n",
    "    listings_cleaned[\"popular\"] = (listings_cleaned[\"availability_365\"] <= 92).astype(int)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    X = listings_cleaned[[\"price\", \"accommodates\"]]\n",
    "    y = listings_cleaned[\"popular\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    listings_cleaned = listings_cleaned.copy()\n",
    "    listings_cleaned.loc[:, \"predicted_popularity\"] = clf.predict(X)\n",
    "\n",
    "    popular_listings = listings_cleaned[listings_cleaned[\"predicted_popularity\"] == 0]\n",
    "    print(popular_listings[\"listing_url\"])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Accuracy of model:\", accuracy)\n",
    "    # check significance\n",
    "    importances = clf.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    for feature, importance in zip(feature_names, importances):\n",
    "        print(feature, importance)\n",
    "    return mse\n",
    "\n",
    "# while I used three different machine learning methods, I only show Decision Tree classification\n",
    "# because it was consistently the most accurate.\n",
    "decision_tree(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Does having a profile picture affect the popularity of a host's listing?\n",
    "def pfp_bookings(listings):\n",
    "    \"\"\"\n",
    "    Determines whether the host has a profile picture and the listing’s\n",
    "    number of bookings in the next year to evaluate whether there is a correlation\n",
    "\n",
    "    >>> pfp_bookings(listings_test)\n",
    "    '-88.33333333333334'\n",
    "    \"\"\"\n",
    "    listings[\"num_bookings\"] = 365 - listings[\"availability_365\"]\n",
    "\n",
    "    true_data = listings[listings[\"host_has_profile_pic\"] == \"t\"][\"num_bookings\"]\n",
    "    false_data = listings[listings[\"host_has_profile_pic\"] == \"f\"][\"num_bookings\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot([true_data, false_data], labels=[\"True\", \"False\"])\n",
    "    plt.xlabel(\"Host Has Profile Pic\")\n",
    "    plt.ylabel(\"Number of Bookings\")\n",
    "    plt.title(\"Number of Bookings in a Year vs. Host Profile Picture\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    print(\"Mean bookings with Profile Picture:\", round(true_data.mean(), 2))\n",
    "    print(\"Mean bookings without Profile Picture:\", round(false_data.mean(), 2))\n",
    "    print(\"Median bookings with Profile Picture:\", round(true_data.median(), 2))\n",
    "    print(\"Median bookings without Profile Picture:\", round(false_data.median(), 2))\n",
    "\n",
    "    # Again, I know returned value is not used, but using it for doctest\n",
    "    return (true_data.mean() - false_data.mean())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "pfp_bookings(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implications and Limitations\n",
    "My analysis can be used by urban planners and policymakers to view the density and prices of Airbnbs in\n",
    "different neighborhoods, and this data can be used in monitoring properties and when implementing\n",
    "regulations in the future. Furthermore, it can be used by hosts to analyze whether their properties are likely\n",
    "to be successful based on factors such as price, the number of people it accomodates, their response rate,\n",
    "and their ratings; it also shows how much of an effect on popularity these factors have (significance). Lastly,\n",
    "the interactive map imitates that of the Airbnb app or website; it is a convenient way for customers to view\n",
    "all listings in Seattle and their characteristics.\n",
    "However, listings with empty values may be dropped in some of these functions, exluding those listings\n",
    "from being analyzed. Moreover, these values were last scraped in March, and do not currently reflect\n",
    "updated listings. I also would have liked to be able to view when these Airbnbs were originally listed in order\n",
    "to analyze whether they are becoming more expensive or dense.\n",
    "While many of these functions, such as the host profile pictures, may suggest a correlation, it does not\n",
    "necessarily guarantee causation. The machine learning models are not perfectly accurate and cannot\n",
    "guarantee the popularity of a listing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
